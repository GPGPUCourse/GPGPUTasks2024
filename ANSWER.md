1) Сигнал y1[n] = x[n - 1] + x[n] + x[n + 1] будет проще и быстрее реализовать в модели массового параллелизма потому что этот сигнал зависит только от x[n - 1], x[n] и x[n + 1] которые можно вычислить независимо.
   Сигнал y2[n] = y2[n - 2] + y2[n - 1] + x[n] зависит еще и от своих предыдущих значений, что затрудняет параллельные вычисления, потому что данные значения нужно вычислять последовательно, дожидаясь предыдущих 
   значений.

2) Код дивергенции не произойдет потому что по условию в каждом warp get_local_id(0) принимает значения от 0 до 31, а get_local_size(1) не меняется, тогда так как для каждого потока warp 
   idx = get_local_id(1) + 32 * get_local_id(0), где get_local_size(1) == 32 то idx % 32 = get_local_id(1), а значит не меняется. Тогда условие idx % 32 < 16 одинаково для всех потоков и они все будут выполнять 
   только одну функцию.

3) 
   (a) Обращение к памяти будет coalesced и 32 кеш линий записей в WG, потому что формула возвращает соседние индексы для соседних потоков. Так как размер float равен 4 байта то один warp пишет 32 * 4 = 128 байт и 
       это умещается в одну кэш-линию и таких записей будет 32.
   (b) Обращение к памяти не будет coalesced и произойдет 1024 кэш-линий записей, потому что внутри warp индекс получается как get_local_id(0) + 32 * get_local_id(1), при этом get_local_id(0) от 0 до 31 а get_local_id(1)
       не меняется, поэтому индексы будут последовательными. Так как 32 потока в warp обращаются к последовательным адресам которые в одной кэш линии то так как всего 32 warp то записей 32 * 32 = 1024.
   (c) Обращение к памяти будет calesced и количество кеш линий записей будет 64, потому что так же делаются записи подряд. Так как сдвиг на 1 байт то из-за выравнивания будет 2 кэш линий в warp и количество 
       кэш линий записей будет 32 * 2 = 64.
