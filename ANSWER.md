## Параллелизуемость

**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

**Решение:** проще будет реализовать первый сигнал. Потому что вычисление `y1[i]` никак не зависит от вычислений соседних потоков в варпе и рабочей группе. 

Второй же сигнал в наивной реализации реализации влечёт за собой зависимость по данным, а значит и синхронизацию, что усложняет и код, и замедляет его


**2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?


**Решение:** warp размера 32, work-item меняется сначала по X, потом по Y, потом по Z. Поэтому рабочая группа будет укладываться на варпы линейками по оси X.

Внутри warp один instruction pointer, поэтому внутри варпа `get_local_id(1)` - константа. Т.к. `get_local_size(1) = 32` - размер рабочей группы по оси Y. Из этого получаем, что `idx = get_local_id(1)`, что не меняется внутри варпа.

Поэтому code divergence не произойдёт


**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
 на warp/wavefront-ы таким образом что внутри warp/wavefront
 номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Решение:** Да, такое обращение в памяти будет coalesced. Потому что из всех параметров в наших условиях меняется только `get_local_id(0)`, но меняется оно от 0 до 31, поэтому coalesced

Так как `sizeof(float) = 4`, то внутри варпа будет загружена только 1 кеш-линия, а внутри рабочей группы 32


(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Решение:** Нет, такое обращение не будет coalesced. Здесь меняется `get_local_id(0)` и домножается на размер рабочей группы, то есть 32.

Мы будет внутри варпа делать транзакции к `data[y]`, `data[y + 32]`, `data[y + 64]`..., т.е. внутри варпа будем ждать осуществления каждой из транзакций

Будет совершено `32 * 32 = 1024` записи кеш-линий

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Решение:** также, как и в (a) это обращение будет coalesced. Но т.к. кеш-линии загружаются по выровненным адресам, то обращение `data[1]` загрузит линейку `data:data + 31`. Поэтому последний элемент будет подгружаться ещё 1 транзакцией

Поэтому всего будет `2 * 32 = 64` записи в кеш линии


