# Задание 2. Теоретическое задание: параллелизуемость/code divergence/memory coalesced access

**Дедлайн**: 23:59 29 сентября.

**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

**Ответ: Первый** сигнал будет проще т.к:
* Читаем только одну переменную, причем соседние индексы (справимся за одну транзакцию, надеюсь), получится все запараллелить
* В первом сигнале нет рекурсии, во втором у нас не получится запустить несколько потоков

**2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?

**Ответ: нет**. Т.к. если посчитать индексы исходя из формулы idx, размера рабочей группы, размера warp'а и характера изменения WorkItem (x -> y -> z), получим:

```
0, 32, 64, 96, ..., 992 <- первый варп (idx % 32 = 0)
1, 33, 65, 97, ..., 993 <- второй варп (idx % 32 = 1)
...
31, 63, 95, 127, ..., 1027 <- последний варп (idx % 32 = 31)
```

Каждый варп получит по одному столбцу рабочей группы (32, 1). Очевидно, что внутри каждого варпа idx % 32 будет 
возвращать одно и то же значение, соответственно, все потоки внутри каждого из варпов будут идти по
общей ветке if и code divergence не случится.

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ: да, 32 обращения**. Т.к. если взять в расчет условие получим обращение по индексам: 

```
0, 1, 2, 3, ..., 31 - для первого варпа
32, 33, 34, ..., 63 - для второго варпа
и так далее...
```

Соответственно, каждый варп будет делать одно обращение к памяти (32 * sizeof(float) = 128), причем, соседние потоки в 
варпе будут обращаться к соседним индексам в памяти и будет 100% coalesced-доступ. При этом рабочая группа будет 
разделена между 32мя варпами, каждый из которых сделает по одному обращению в память

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ: нет, 1024**. Т.к. здесь индексы обращений будут выглядеть следующим образом:

```
0, 32, 64, 96, ..., 992 - для первого варпа
1, 33, 65, 97, ..., 993 - для второго варпа
и так далее...
```

Потоки внутри одного варпа обращаются к удаленным индексам (даже не лежащим в пределах одной кэш-линии). Соответственно, 
если кэша на запись у нас нет (?), то каждый поток каждого варпа потребует своей транзакции для записи (32*32=1024).

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ: да, 32 обращения**. Почти то же самое, что в 3.а, только со сдвигом. Индексы:

```
1, 2, 3, 4, ..., 32 - для первого варпа
33, 34, 35, 36, ..., 64 - для второго варпа
и так далее...
```

Соответственно, каждый варп будет делать одно обращение к памяти (32 * sizeof(float) = 128), причем, соседние потоки в
варпе будут обращаться к соседним индексам в памяти и будет 100% coalesced-доступ. При этом рабочая группа будет
разделена между 32мя варпами, каждый из которых сделает по одному обращению в память