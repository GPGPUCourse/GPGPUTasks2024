1. Вычисление каждого отдельного элемента y1 зависит только от входного сигнала x, поэтому y1[i] можно вычислять независимо и это вычисление естественным образом реализуется на GPU.
   В случае же с y2, y2[i] зависит от y2[i-1], поэтому (если использовать исходные формулы) y2 придётся вычислять последовательно, а так как вычисление каждого элемента очень простое, мы не получим выигрыша от массового параллелизма GPU

2. Так как мы знаем размеры рабочей группы, можно упростить выражение под `if`'ом: 
   ```
   idx % 32 < 16 <=>
   (get_local_id(1) + get_local_size(1) * get_local_id(0)) % 32 < 16 <=>
   (get_local_id(1) + 32 * get_local_id(0)) % 32 < 16 <=>
   get_local_id(1) % 32 < 16 <=>
   get_local_id(1) < 16
   ```
   Внутри одного варпа будут исполняться потоки с фиксированными индексами по 1-му и 2-му измерениям и со всеми возможными по 0-му, так как размер по 0-му измерению совпадает с количеством потоков в варпе. Значит `get_local_id(1) < 16` --- это константа внутри каждого варпа, то есть code divergence не произойдёт.

3. 
   a) Индексы доступа в рамках одного варпа пробегают все значения от `0 + 32 * get_local_id(1)` до `31 + 32 * get_local_id(1)` c шагом `1`, поэтому мы имеем идеально выровненный последовательный доступ к памяти, по `128 / (sizeof(float) * 32) == 1` кеш-линий на варп (coalesced), а вся рабочая группа сделает `1*32=32` записей
   
   b) Индексы доступа в рамках одного варпа пробегают все значения от `get_local_id(1) + 32 * 0` до `get_local_id(1) + 32 * 31` c шагом `32`, то есть каждый варп использует `32` кеш-линии и только 4 байта в каждой из них (не coalesced). Более того, все 32 записи попадут в один банк памяти, то есть записи будут непараллельными. Вся рабочая группа сделает `32*32=1024` записей 

   c) Ситуация похожа на (a), но теперь запись не выровнена, поэтому она заденет `2` кеш-линии на варп, используя лишь половину индексов в них (не coalesced), а вся рабочая группа сделает `2*32=64` записей