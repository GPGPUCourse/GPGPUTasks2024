1. 1. Сигнал `y_1[n] = x[n - 1] + x[n] + x[n + 1]`:
      - Для вычисления каждого значения `y_1[n]` требуются три соседних значения сигнала `x[n]`: `x[n-1]`, `x[n]`, и `x[n+1]`.
       - Эти вычисления независимы друг от друга для каждого n, что позволяет выполнить их параллельно для всех n.
       - Вычисления сводятся к простым операциям сложения, что отлично подходит для массового параллелизма на GPU.

   2. **Сигнал `y_2[n] = y_2[n - 2] + y_2[n - 1] + x[n]`**:
       - Здесь присутствует зависимость от предыдущих значений `y_2[n - 2] \) и \( y_2[n - 1]`.
       - Необходимо последовательно вычислять каждое `y_2[n]`, что ограничивает параллелизм и снижает эффективность использования GPU.
   3. - Первый сигнал проще и быстрее реализовать на модели массового параллелизма на GPU, так как его элементы могут быть вычислены независимо друг от друга.
      - В случае со вторым, из-за последовательной зависимости между элементами, эффективная параллельная реализация на GPU невозможна.

2. Условие ветвления равносильно `get_local_id(1) < 16`, так как размер рабочей группы по `Y` равен 32. Получается, что для
   все `x` из одной рабочей группы провалятся в одну ветку, а значит `code divergence` не будет.

3. 1.  Да, обращение к памяти будет coalesced, так как потоки внутри одного warp/wavefront обращаются к последовательным ячейкам памяти.
       Это происходит потому, что индексы данных для всех потоков увеличиваются последовательно на 1 в пределах warp (от 0 до 31),
       что идеально подходит для кэш-линии размером 128 байт (32 потока * 4 байта для float = 128 байт).
       Поскольку каждый warp записывает по одной кэш-линии (128 байт), в одной рабочей группе произойдет запись 32 кэш-линий.
   2.  При изменении get_local_id(0) внутри warp индекс меняется на 32, 64, 96 и так далее.
       Это приводит к шагу в 32 элемента в массиве при последовательном изменении get_local_id(0).
       Нет, обращение не будет coalesced, потому что потоки внутри warp обращаются к памяти с шагом 32 элемента (индексы: 0, 32, 64, ..., 992).
       Это означает, что данные разбросаны через 32 элемента, и для каждого потока потребуется отдельная кэш-линия.
       Для каждого warp потребуется 32 кэш-линии. Всего в рабочей группе 32 warps, значит, потребуется 32 * 32 = 1024 кэш-линий.
   3. Да, обращение будет почти coalesced, потому что потоки внутри warp снова обращаются к последовательным ячейкам памяти (индексы: 1, 2, 3, ..., 32).
      Единственное отличие — это то, что доступ начинается с индекса 1, а не с 0.
      Каждая кэш-линия покрывает 32 элемента. Поскольку индексы для потоков начинаются с 1 (и продолжаются до 32),
      первый warp записывает данные с 1 по 32, что затрагивает 2 кэш-линии (первую — для элементов 1–31 и вторую — для элемента 32).
      В итоге, для каждого warp потребуется 2 кэш-линии. Так как в рабочей группе 32 warps, потребуется 32 * 2 = 64 кэш-линии.
