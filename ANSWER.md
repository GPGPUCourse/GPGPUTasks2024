Как и говорилось на лекции, sum03 с циклом и coalesced доступом имеет наилучшие результаты. Скорее всего, это из-за того, что все-таки вызов kernel-ов и scheduling на видеокарте не бесплатный (когда я писал a+b у меня удалось выжать только 45 Gflops из 21 Tflops обещанных - очевидно существует весомый оверхед обращения к памяти и вообще исполнения маленьких кернелов, вероятно из-за scheduling-а на SM). Ну а цикл + coalesced доступ гарантирует, что warp всегда совершает интересную работу, и быстро получает память (даже несмотря на то, что в моей реализации она так себе выровнена - я пытался улучить это чтобы каждый поток делал шаг кратный 128 байтам, но это не привело к улучшению результатов).

По поводу остального - все довольно логично. Global atomic оптимизируется на уровне драйвера, и работает неплохо. Реализации с циклом выигрывают, как я уже говорил, за счет того, что они просты для scheduler-а, а последующий глобальный атомик очень дешевый. Вариант с локальной памятью неплох (кажется, он имеет лучший паттерн обращения к памяти), но проигрывает по объему полезных вычислений, так как по сравнению с циклом итерации после первых нескольких заставляет часть потоков простаивать.

Ну и вариант с большим деревом редукции проигрывает из-за своей вычислительной простоты. Хотя, наверняка, если заменить + на какую-нибудь более вычислительно сложную ассоциативную функцию, это может быть оптимальное решение. Можно было бы также попробовать сделать дерево шире (то есть не бинарным, а n-арным), но тогда это просто превращается в вариант 3, в котором атомик в конце заменили на рекурсию. Я сделал это в "бонусном" эксперименте 6, но это не привело к улучшению результатов. Все-таки атомик - это проще и быстрее.

Наконец, я уже упомянул, что я пытался улучшить sum03 за счет выравнивания stride-а, и у меня получились результаты только хуже (примерно 110 B/s против 130 B/s - надо расскоментировать строку помеченную с "why????"). Я не знаю почему, и вот этот результат довольно интересный :)
