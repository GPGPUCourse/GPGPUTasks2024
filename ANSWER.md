**1)** Пусть на вход дан сигнал x[n], а на выход нужно дать два сигнала y1[n] и y2[n]:

```
 y1[n] = x[n - 1] + x[n] + x[n + 1]
 y2[n] = y2[n - 2] + y2[n - 1] + x[n]
```

Какой из двух сигналов будет проще и быстрее реализовать в модели массового параллелизма на GPU и почему?

**Ответ:** Если внимательно посмотреть, то мы можем заметить, что `y2` считается с использованием предыдущих версий себя.
Тогда как для подчсёта `y1` требуется всего лишь значение элементов из `x`, причём, находящиеся рядом.
Из-за этого, структура для `y1` принципиально итеративна. 

**2)** Предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Напоминание: инструкция исполняется (пусть и отмаскированно) в каждом потоке warp/wavefront если хотя бы один поток выполняет эту инструкцию неотмаскированно. Если не все потоки выполняют эту инструкцию неотмаскированно - происходит т.н. code divergence.

Пусть размер рабочей группы (32, 32, 1)

```
int idx = get_local_id(1) + get_local_size(1) * get_local_id(0);
if (idx % 32 < 16)
    foo();
else
    bar();
```

Произойдет ли code divergence? Почему?

**Ответ:** Мы знаем, что `get_local_size(1)` всегда равен 32, значит, его можно не учитывать в подсчёте 
(всё равно по модулю мы его выкинем).
Тогда, у нас получается 
```
idx % 32 == (local_id(1) + 32 * local_id(0)) % 32 == local_id(1) % 32
```
Значит, у нас всё зависит от `local_id(1)`, который не изменяется

**3)** Как и в прошлом задании предположим что размер warp/wavefront равен 32 и рабочая группа делится
на warp/wavefront-ы таким образом что внутри warp/wavefront
номер WorkItem по оси x меняется чаще всего, затем по оси y и затем по оси z.

Пусть размер рабочей группы (32, 32, 1).
Пусть data - указатель на массив float-данных в глобальной видеопамяти идеально выравненный (выравнен по 128 байтам, т.е. data % 128 == 0). И пусть размер кеш линии - 128 байт.

(a)
```
data[get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** `get_local_id(0)` будет следовать друг за другом, поэтому у нас будет coalesced обращение. 
В одну кеш-линию у нас умещается 32 значения float (32*4 байт) из-за чего в одной рабочей группе у нас будет задействовано
32 кеш-линии на запрос

(b)
```
data[get_local_id(1) + get_local_size(1) * get_local_id(0)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** Нет, в данном случае использование памяти будет попадать по разным кеш-линиям 
(`get_local_id(0)` обновляется реже `get_local_id(1)`). Обновление будет происходить сразу на 32 значения. 
Тогда, при запросе каждого в рабочей группе, мы получим обращение всего в 32*32 = 1024 кеш линиям.

(c)
```
data[1 + get_local_id(0) + get_local_size(0) * get_local_id(1)] = 1.0f;
```

Будет ли данное обращение к памяти coalesced? Сколько кеш линий записей произойдет в одной рабочей группе?

**Ответ:** Да, тут как и в первом примере, только теперь в каждом warp нам необходимо будет использовать ещё одну кеш-линию
(`+1` в данном случае заставит нас брать не по кеш-линии в 32 значения, а захватить 33, которое будет в другой кеш-линии)
Значит, каждый раз нам надо будет "затронуть" на 1 линию больше, чем в примере (а). Получаем 64 линии.
