# Задание 2. Теоретическое задание: параллелизуемость/code divergence/memory coalesced access

**1)**

Сигнал `y1[n] = x[n - 1] + x[n] + x[n + 1]`, который имеет зависимость только от входных данных считать проще и удобнее параллелить, тк нет завязки на порядок вычислений.\
Второй сигнал имеет зависимость на свои же предыдущие значения, тогда их нужно будет считать последовательно, что хуже укладывается на модель массового параллелизма гпу

**2)** 

Не произойдет, потому что по условию warp будет накладываться по строчкам WG (на всю ось x), то есть индекс по оси y -- `get_local_id(1)` будет одинаковой внутри потоков варпа.
Ну и так как размер по y совпадает с размером варпа (32), то условие внутри if-a эквивалентно: `if (get_local_id(1) % 32 < 16)`, значит все потоки пойдут в одну и ту же ветку.

**3)**

(a) Coalesced access, 32 кеш линий записей в WG\
Cоседние потоки в варпе записывают данные в соседние ячейки памяти (без сдвигов), значит обращения склеятся.\
`sizeof float == 4b`, поэтому один варп пишет `4 * 32 = 128` байт, значит варп пишет в одну линейку. Всего таких записей будет 32 (размер WG по оси y).

(b) Не Coalesced access, 1024 кеш линий записей в WG\
В варпе пишем данные в элементы с прыжками в 128 байт, так как `get_local_id(1)` постоянен (выяснили в задании 2), `get_local_size(0)` (размер по х) равен 32, `get_local_id(0) = [0..31]` (для соседних потоков отличается на 1), `sizeof float == 4`
Итого, для соседних потоков записи происходят в ячейки с прыжком в `get_local_size(0) * sizeof(float) = 32 * 4 = 128` байт, значит каждый поток пишет в свою кеш линейку, внутри варпа будет записи в 32 кеш линейки, внутри WG будет `32 * 32 = 1024` записей.

(c) Coalesced access, 64 кеш линий записей в WG\
Пишем в соседние ячейки, аналогично рассуждениям для (a). Но здесь есть сдвиг в 4 байта, а в кеш линию выровненные участки памяти подгружается, поэтому потребуется 2 кеш линейки в рамках варпа (видимо для последнего потока потребуется своя кеш линия).
