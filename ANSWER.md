# Сравнение алгоритмов

По проведенным экспериментам заметно, что work-efficient реализация работает значительно быстрее наивной, причем чем больше размер массива,
тем сильнее видно различие.

Вообще я полагаю, что наивную реализацию можно было написать чуть более
оптимально, возможно вставив копирование из a в b в kernel, но у меня лапки. Я не думаю, что это повлияет на результат так сильно, что 
work-efficient перестанет выигрывать в 4-5 раз на максимальном тесте.

Отмечу, что у work-efficient версии есть ряд существенных недостатков. Как минимум то, что она совершает больше вызовов к кернелу (что по моему опыту стоит довольно дорого) и очень не оптимально действует в плане памяти. У нее нет coalesced доступов начиная со второго уровня и до предпоследнего включительно, и в теории первые и последние 6 (= log2(warp_size * 2)) уровня этой версии читают примерно столько же памяти, сколько и наивная. Однако у нее есть большой плюс: она не требует глобальной синхронизации, и в связи с этим работает in-place всего с одним массивом. К тому же, уровней обычно больше, чем 6. Если представить, что кеш бесконечный, на максимальном тесте можно оценить общее количество доступов к линиям памяти как 7 * 2 * n / line_size (6 на первых 6 уровнях + 1 на последующих * 2 редукции: вниз и вверх * кол-во линий в массиве), что уже примерно в 2 раза быстрее наивной версии (которая 23 уровня читает всю память), и это без учета копирований памяти.

И тут мне пришла безумная идея: что если еще сильнее улучшить доступ к памяти? В gpu gems написана идея с добавлением дырок в массив, чтобы уменьшить количество bank conflicts. В принципе такая идея и в CPU HPC имеет место быть, чтобы уменьшить количество вытеснений из кеша недостаточной ассоциативности. Но, что если переставить элементы массива так, чтобы конфликтов кеша было еще меньше?

Если применить перестановку, которая разворачивает биты всех индексов, то верхняя часть дерева редукции work-efficient реализации становится мега-супер coalesced. Естественно, сама процедура перестановки не coalesced, но если получится, что массив можно какое-то время хранить в таком виде (типа если доступ в него редкий, или за него можно заплатить 26-ю битовыми операциями за перестановку битов в индексе), то мооооожет быть это в теории и даст выигрыш.

А, естественно есть еще нижняя часть редукции, там надо применить перестановку `rev((rev(x) + 1) % n)` чтобы все было coalesced.

Вряд ли это поможет, потому что теперь нам нужна дополнительная память на вторую перестановку (там нужен циклический сдвиг массива), и вообще процедуры перестановки мега-не-coalesced, но... блин, а что если?..

К тому же, я покопал чуть-чуть, и подобных реализаций не нашел. Вряд ли я самый умный, и это что-то полезное. Наверняка большего выигрыша можно добиться простыми методами, типа копированием в локальную память, или совершением большего объема работы за warp.

Thanks for coming to my TED talk.
