# Транспонирование матрицы

Я не получил особо интересных результатов. Наивная версия < С локальной памятью < С хорошим доступам к банкам. Интересно лишь то, что ускорение не особо настолько большое, как я ожидал. Примерно на 30% быстрее при избавлении от non-coalesced доступа (видимо тут решает кеш) и 1-2% при улучшении обращения к локальной памяти (зато это улучшение есть всегда, хотя оно не большое).

# Умножение матриц

Самый интересный результат здесь заключается в том, что последняя версия побеждает примерно в 2 раза при правильном подборе параметров (3.14 TFlops против 1.66 TFlops), при том, что количество инструкций уменьшилось точно меньше чем в 2 раза (каждые 8 load-ов и 4 fma превращаются в 5 load-ов и 4 fma). Получается, что есть что-то еще, что сильно влияет на ускорение. Скорее всего дело в кеше (изменился паттерн обращения к глобальной памяти => кеш стал лучше утилизироваться), но это просто теория на основе моих знаний о кеше на CPU. Я могу также предполагать, что дело в количестве переключений между рабочими группами, или в нагрузке на планировщик, или в ограничение скорости чтения из глобальной памяти.
