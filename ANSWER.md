**1)** Легче будет реализовать `y1`, так как его значения не зависят от предыдущих значений `y1`, к тому же сложение ассоциативно и коммутативно, то есть присутствует множество способов разбить эту задачу на подзадачи.
В то же время сигнал `y2` требует подсчёта предыдущих значений, из-за чего реализовать подсчёт этого сигнала будет намного труднее (как минимум требуется затратная синхронизация, чего в первом случае можно избежать).

**2)** Имеем `get_local_size(1) == 32`, то есть `idx % 32` зависит только от `y`-координаты потока, но размер warp'а равен размеру рабочей группы по `x`, следовательно для каждого warp'а значение `get_local_size(1)` постоянно, а значит code divergence не происходит.

**3)**
(a)
Данное обращение будет coalesced, так как `get_local_id(0)` меняется чаще всего и обращение к памяти будет последовательным. Всего каждый warp запишет `32 * sizeof(float) == 128` байт, на что понадобится одна cache линия. Одна рабочая группа разбивается на 32 warp'а, следовательно произойдёт запись 32 cache линий.

(b)
Нет, не будет, так как каждый поток записывает данные в адрес, на 128 байт больший предыдущего, что равняется размеру cache линии. Каждый warp записывает на 32 cache линии, всего warp'ов 32, итого 1024 cache линии.

(с)
Скорее да, чем нет, так как потоки обращаются к последовательным элементам в памяти, но делают это с отступом в 4 байта. Каждый warp использует 2 cache линии (вторую только для последнего потока), всего warp'ов 32, итого 64 cache линии.

